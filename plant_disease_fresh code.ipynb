{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "plant disease.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP+O1fO9mWK/VpObwhEOAjO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imranrahman1997/Machine-Learning_projects/blob/master/plant_disease_fresh%20code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDs17sqK8lmt"
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhXaWu4J9FQk"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyzK12Xn9301"
      },
      "source": [
        "\n",
        "#before importing the dataset we want to use this code\n",
        "# The Kaggle API client expects this file to be in ~/.kaggle,\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# This permissions change avoids a warning on Kaggle tool startup.\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nDeWVK9-ACp"
      },
      "source": [
        "!kaggle datasets download -d noulam/tomato"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16ZZLsJ8_eth"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "file_name = \"/content/tomato.zip\"\n",
        "\n",
        "with ZipFile(file_name, \"r\") as zip:\n",
        "  zip.extractall()\n",
        "  print(\"done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0Qr-RzkRdyI"
      },
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wZCjzDrRztR"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjxTvvA8RzyB"
      },
      "source": [
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "config = ConfigProto()\n",
        "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
        "config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config=config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zv_EC8FIRz2q"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fm5UseLaRz5O"
      },
      "source": [
        "IMAGE_SIZE = [224, 224]\n",
        "\n",
        "train_path = \"/content/Datasets/train\"\n",
        "test_path = \"/content/Datasets/test\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ir12Z4RzRz9w"
      },
      "source": [
        "inception = InceptionV3(input_shape = IMAGE_SIZE + [3], weights='imagenet', include_top= False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drliu5tgR0D8"
      },
      "source": [
        "for layer in inception.layers:\n",
        "  layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5tCSOpYR0LA"
      },
      "source": [
        "#NUMBER of out put classes\n",
        "folders = glob(\"/content/Datasets/train/*\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2hLKrr7R0Pa"
      },
      "source": [
        "#our flatten layer\n",
        "x = Flatten()(inception.output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8UGBDE6Leox"
      },
      "source": [
        "import tensorflow as tf\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "      if(logs.get('accuracy')>0.97):\n",
        "        print(\"\\nReached 60% accuracy so cancelling training!\")\n",
        "        self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjO4UvkiR0R7"
      },
      "source": [
        "prediction = Dense(len(folders), activation = 'softmax')(x)\n",
        "\n",
        "#creat model object\n",
        "model = Model(inputs = inception.input , outputs = prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMYOjvjwR0WV"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLcnFs3-R0bB"
      },
      "source": [
        "model.compile(\n",
        "    loss = 'categorical_crossentropy',\n",
        "    optimizer = 'adam',\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6_-PL2tR0d4"
      },
      "source": [
        "#use image generator\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   shear_range  = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVnG3JDMR0hV"
      },
      "source": [
        "training_set = train_datagen.flow_from_directory('/content/Datasets/train',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 18,\n",
        "                                                 class_mode = 'categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTqhkUcnR0Yy"
      },
      "source": [
        "test_set = test_datagen.flow_from_directory(\"/content/Datasets/test\",\n",
        "                                           target_size  = (224, 224),\n",
        "                                           batch_size = 18,\n",
        "                                           class_mode = \"categorical\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3Kxm38AR0Uf"
      },
      "source": [
        "r = model.fit_generator(\n",
        "  training_set,\n",
        "  validation_data=test_set,\n",
        "  epochs=70,\n",
        "  steps_per_epoch=len(training_set),\n",
        "  validation_steps=len(test_set),\n",
        "  callbacks=[callbacks]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdSJ2GirR0No"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExLSyncGR0Iy"
      },
      "source": [
        "# plot the loss\n",
        "plt.plot(r.history['loss'], label='train loss')\n",
        "plt.plot(r.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('LossVal_loss')\n",
        "\n",
        "# plot the accuracy\n",
        "plt.plot(r.history['accuracy'], label='train acc')\n",
        "plt.plot(r.history['val_accuracy'], label='val acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('AccVal_acc')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvGnk4UQR0HH"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model.save(\"model_inception.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2fDmsGcR0CP"
      },
      "source": [
        "y_pred = model.predict(test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwv6TzCZR0A2"
      },
      "source": [
        "\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwkDa-1wRz7t"
      },
      "source": [
        "import numpy as np\n",
        "y_pred = np.argmax(y_pred, axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPi4-72-RzwJ",
        "outputId": "27ba599b-5368-40e9-c12e-786561785c60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 4, 9, ..., 8, 9, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beaj3V4yinTn"
      },
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "\n",
        "  # predicting images\n",
        "  path = '/content/' + fn\n",
        "  img = image.load_img(path, target_size=(224, 224,3))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images)\n",
        "\n",
        "\n",
        "  print(classes)\n",
        "\n",
        "classes2 = np.argmax(classes, axis=1)\n",
        "\n",
        "if classes2[0] == 0:\n",
        "        print('it is Tomato_Yellow_Leaf_Curl_Virus')\n",
        "elif classes2[0] == 1:\n",
        "        print('It is Tomato_mosaic_virus')\n",
        "elif classes2[0] == 2:\n",
        "        print('It is a Septoria_leaf_spot')\n",
        "elif classes2[0] == 3:\n",
        "        print('It is a Spider_mites')\n",
        "elif classes2[0] == 4:\n",
        "        print('It is a Late_blight')\n",
        "elif classes2[0] == 5:\n",
        "        print('It is a healthy')\n",
        "elif classes2[0] == 6:\n",
        "        print('It is a Early_blight')\n",
        "elif classes2[0] == 7:\n",
        "        print('It is a Bacterial_spot')\n",
        "elif classes2[0] == 8:\n",
        "        print('It is a Leaf_Mold')\n",
        "elif classes2[0] == 9:\n",
        "        print('It is a Target_Spot')\n",
        "else:\n",
        "        print('Can\\'t recognize the image')\n",
        "\n",
        "print('done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swv7icVBinWl"
      },
      "source": [
        "folders"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOn6dRsUinZi"
      },
      "source": [
        "test_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAy5MGWwJs6w"
      },
      "source": [
        "class_dict = training_set.class_indices\n",
        "class_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdYJJQ5uJs_M"
      },
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "\n",
        "  # predicting images\n",
        "  path =  fn\n",
        "  img = image.load_img(path, target_size=(224, 224,3))\n",
        "  x = image.img_to_array(img)\n",
        "  x = x / 255\n",
        "  x = x.reshape(-1, 224, 224, 3)\n",
        "  images = np.vstack([x])\n",
        "  prediction = model.predict(images)\n",
        "\n",
        "\n",
        "  print(prediction)\n",
        "\n",
        "\n",
        "\n",
        "if np.argmax(prediction) == 0:\n",
        "    print(\"Tomato___Bacterial_spot\")\n",
        "elif np.argmax(prediction) == 1:\n",
        "    print(\"Tomato___Early_Blight\")\n",
        "elif np.argmax(prediction) == 2:\n",
        "    print(\"Tomato___Late Blight\")\n",
        "elif np.argmax(prediction) == 3:\n",
        "    print(\"Tomato___Leaf Mold\")\n",
        "elif np.argmax(prediction) == 4:\n",
        "    print(\"Tomato___Septoria Leaf Spot\")\n",
        "elif np.argmax(prediction) == 5:\n",
        "    print(\"Tomato___Spider mites\")\n",
        "elif np.argmax(prediction) == 6:\n",
        "    print(\"Tomato___Target Spot\")\n",
        "elif np.argmax(prediction) == 7:\n",
        "    print(\"Tomato___Yellow Leaf Curl Virus\")\n",
        "elif np.argmax(prediction) == 8:\n",
        "    print(\"Tomato___Mosaic Virus\")\n",
        "else:\n",
        "    print(\"Tomato___Healthy\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XPxfo24JtDa"
      },
      "source": [
        "model.save(\"model_inception.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}